{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9c516d",
   "metadata": {},
   "source": [
    "# How to perform experiments with damast\n",
    "\n",
    "One of the main motivation of this library is to facilitate the development and evaluation of Machine-Learning models.\n",
    "Hence, 'damast' offers a mini-framework and API to simplify the development of machine learning models.\n",
    "This requires a 'hopefully' minimal set of constraints - as what is envisioned by the authors of this library - so that researchers and ML-starters have lower entry barrier into running machine learning.\n",
    "\n",
    "That being said, we give an example here on a minimal experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba76d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'damast[ml]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6674a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of modules used for this example\n",
    "from collections import OrderedDict\n",
    "from typing import List, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# For performance reasons the underlying data handling library is 'polars'\n",
    "import polars\n",
    "\n",
    "# The current development has focused on a keras+tensorflow based Machine Learning setup\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import damast\n",
    "from damast.data_handling.transformers.cycle_transformer import CycleTransformer\n",
    "# You can define custom units to annotate data, but otherwise astropy units will be used\n",
    "from damast.core.units import units\n",
    "# Data ranges can be defined as list, or marked with a lower-bound (min), upper-bound (max)\n",
    "from damast.core.data_description import MinMax, CyclicMinMax\n",
    "# The AnnotatedDataFrame combines a data specification and actual 'numeric' data\n",
    "from damast.core.dataframe import AnnotatedDataFrame\n",
    "# An AnnotatedDataFrame contains MetaData to describe the data\n",
    "from damast.core.metadata import MetaData\n",
    "\n",
    "# Data processing is centered around a DataProcessingPipeline which consists of multiple PipelineElement being run\n",
    "# in sequence\n",
    "from damast.core.dataprocessing import DataProcessingPipeline, PipelineElement\n",
    "\n",
    "\n",
    "# To allow the machine learning process to be simplified, we offer a 'BaseModel' that should be inherited from\n",
    "from damast.ml.models.base import BaseModel\n",
    "\n",
    "# The experiment setup\n",
    "from damast.ml.experiments import Experiment, LearningTask, ForecastTask, ModelInstanceDescription, TrainingParameters\n",
    "\n",
    "# Allow to generate data for this particular example that uses data from the maritime domain\n",
    "from damast.domains.maritime.ais.data_generator import AISTestData, AISTestDataSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ff3ae",
   "metadata": {},
   "source": [
    "To illustrate a full experiment, we require a data processing pipeline to be set up. This pipeline will extract all those features, that are necessary to train the Machine Learning model(s). The pipeline will run transformations on the data, as provided here by a LatLonTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8163e",
   "metadata": {},
   "source": [
    "The selected example model here, will require the above listed features as input - and provide a likewise-shaped output (for illustration purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(BaseModel):\n",
    "    \"\"\"\n",
    "    This is a placeholder ML model that illustrates the minimal\n",
    "    requirements.\n",
    "    \"\"\"\n",
    "    input_specs = OrderedDict({\n",
    "        \"lat_x\": {\"length\": 1},\n",
    "        \"lat_y\": {\"length\": 1},\n",
    "        \"lon_x\": {\"length\": 1},\n",
    "        \"lon_y\": {\"length\": 1}\n",
    "    })\n",
    "\n",
    "    output_specs = OrderedDict({\n",
    "        \"lat_x\": {\"length\": 1},\n",
    "        \"lat_y\": {\"length\": 1},\n",
    "        \"lon_x\": {\"length\": 1},\n",
    "        \"lon_y\": {\"length\": 1}\n",
    "    })\n",
    "\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 features: List[str],\n",
    "                 timeline_length: int,\n",
    "                 output_dir: Path,\n",
    "                 targets: Optional[List[str]] = None):\n",
    "        self.timeline_length = timeline_length\n",
    "\n",
    "        super().__init__(name=name,\n",
    "                         output_dir=output_dir,\n",
    "                         features=features,\n",
    "                         targets=targets)\n",
    "\n",
    "    def _init_model(self):\n",
    "        features_width = len(self.features)\n",
    "        targets_width = len(self.targets)\n",
    "\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            keras.layers.Flatten(input_shape=[self.timeline_length, features_width]),\n",
    "            keras.layers.Dense(targets_width)\n",
    "        ])\n",
    "\n",
    "\n",
    "class BaselineA(Baseline):\n",
    "    \"\"\"Placeholder Model to illustrate the use of multiple models\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class BaselineB(Baseline):\n",
    "    \"\"\"Placeholder Model to illustrate the use of multiple models\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce825648",
   "metadata": {},
   "source": [
    "This example operates with synthetic, i.e. automatically generated data which is specific to the maritime domain.\n",
    "You will see a previous of the first 10 columns when running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a50353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "tmp_path = Path(tempfile.gettempdir()) / \"test-output-ais_preparation\"\n",
    "if tmp_path.exists():\n",
    "    shutil.rmtree(tmp_path)\n",
    "tmp_path.mkdir(parents=True)\n",
    "\n",
    "pipeline = DataProcessingPipeline(name=\"ais_preparation\",\n",
    "                                  base_dir=tmp_path) \\\n",
    "    .add(\"lat_cycle_transform\", CycleTransformer(n=180), name_mappings={\"x\": \"lat\"})\\\n",
    "    .add(\"lon_cycle_transform\", CycleTransformer(n=90), name_mappings={\"x\": \"lon\"})\n",
    "features = [\"lat_x\", \"lat_y\", \"lon_x\", \"lon_y\"]\n",
    "\n",
    "data = AISTestData(1000)\n",
    "adf = AnnotatedDataFrame(dataframe=data.dataframe,\n",
    "                         metadata=MetaData.from_dict(data=AISTestDataSpec.copy()))\n",
    "dataset_filename = tmp_path / \"test.hdf5\"\n",
    "adf.save(filename=dataset_filename)\n",
    "\n",
    "adf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139d6f7",
   "metadata": {},
   "source": [
    "A central idea to the experiment framework lies in providing a means for a consistent input and output to perform experiments. Hence, define a LearningTask (here: ForecastTask) that collects the learning parameters that define this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_task = ForecastTask(\n",
    "    label=\"forecast-ais-short-sequence\",\n",
    "    pipeline=pipeline, features=features,\n",
    "    models=[ModelInstanceDescription(BaselineA, {}),\n",
    "            ModelInstanceDescription(BaselineB, {}),\n",
    "            ],\n",
    "    group_column=\"mmsi\",\n",
    "    sequence_length=5,\n",
    "    forecast_length=1,\n",
    "    training_parameters=TrainingParameters(epochs=1,\n",
    "                                           validation_steps=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb32d5a",
   "metadata": {},
   "source": [
    "The actual experimentation takes a single LearningTask as input and it will output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48163133",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(learning_task=forecast_task,\n",
    "                        input_data=dataset_filename,\n",
    "                        output_directory=tmp_path)\n",
    "report = experiment.run()\n",
    "    \n",
    "with open(report, \"r\") as f:\n",
    "    print(f.read())        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e524aa52",
   "metadata": {},
   "source": [
    "The outputs of an experiment are collected inside a dedicated (timestamped) folder. This folder will also contain a subfolder for each of the parametrized models that defines a LearningTask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe356d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_experiments = sorted([str(f) for f in Path(experiment.output_directory).glob(pattern=\"*\") if f.is_dir()])\n",
    "print(\"Last experiment in: \", last_experiments[-1])\n",
    "\n",
    "experiment_folder = sorted([str(f) for f in Path(last_experiments[-1]).glob(pattern=\"*\")])\n",
    "file_listing = '\\n'.join(experiment_folder)\n",
    "print(\"Contents:\\n\")\n",
    "print(file_listing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b8f0f",
   "metadata": {},
   "source": [
    "Once the training is running it can be monitored using tensorboard:\n",
    "```\n",
    "    tensorboard --logdir=<experiments-directory>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
