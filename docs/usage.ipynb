{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "We start by exploring the data-processing pipeline part of `DAMAST`.\n",
    "We consider a manufactured dataset of Automatic Identification System (AIS) messages.\n",
    "The data is generated for 150 boats, where the minimal length of a trajectory is 30 messages, and the maximal length is 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import damast.domains.maritime.ais.data_generator as generator\n",
    "\n",
    "data = generator.AISTestData(number_of_trajectories=1000, min_length=25, max_length=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a [polars.LazyFrame](https://docs.pola.rs/api/python/stable/reference/lazyframe/index.html), and we can inspect the first and last 5 messages in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 11 columns, which we will go through in detail.\n",
    "\n",
    "## Data-specification\n",
    "The Maritime Mobile Service Identity (MMSI) used to identify a ship. It *should* be a 9 digit number whose first integer should be between 2 and 7.\n",
    "The data we have generated should contain some invalid numbers. Let us inspect these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from damast.domains.maritime.data_specification import MMSI\n",
    "df = data.dataframe\n",
    "invalid_mmsis = df[(MMSI.min_value>df[\"mmsi\"]) | (df[\"mmsi\"]>MMSI.max_value)]\n",
    "invalid_mmsis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before sending this data to a machine learning algorithm, one would have to filter out invalid data.\n",
    "We can do this by creating a `damast.core.DataSpecification` describing what valid output we would like in our data-frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from damast.core import DataSpecification, MinMax\n",
    "mmsi_spec = DataSpecification(name=\"mmsi\", description=\"Maritime Mobile Service Identity\", representation_type=int,\n",
    "                              value_range=MinMax(MMSI.min_value, MMSI.max_value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have here described what data this column is supposed to describe, how the data is represented in Python, and its minimum and maximum range.\n",
    "Next, we create a `damast.core.MetaData` object that we can apply to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from damast.core import MetaData,ValidationMode\n",
    "metadata = MetaData([mmsi_spec])\n",
    "metadata.apply(df, ValidationMode.UPDATE_DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we do not want to do this process manually per row. Therefore, we can create a `DataSpecification` per row, and let the `damast.core.AnnotatedDataFrame` handle the validation of the data. We can choose between three ways of handling the input data with metadata, we can either use:\n",
    "- `ValidationMode.READONLY`: Reads in the data, checks it against the meta-data and throws an error if the data does not adhere to the data-specification.\n",
    "- `ValidationMode.UPDATE_METADATA`: Update the metadata based on the input in the annotated data-frame. This might change the representation type, column name and valid rages of the data.\n",
    "- `ValidationMode.UPDATE_DATA`: Update data so that it adheres to the meta-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from damast.core.metadata import DataCategory\n",
    "from damast.core.dataframe import AnnotatedDataFrame\n",
    "dataspec = {\n",
    "    \"annotations\": {\"comment\": \"This is a autogenerated test data set\"},\n",
    "    \"columns\": [\n",
    "        {\"name\": \"mmsi\", \"is_optional\": False, \"category\": DataCategory.STATIC,\n",
    "         \"value_range\":{\"MinMax\": {\"min\": MMSI.min_value, \"max\": MMSI.max_value}}},\n",
    "        {\"name\": \"lon\", \"is_optional\": False, \"unit\": \"deg\", \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"lat\", \"is_optional\": False, \"unit\": \"deg\", \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"date_time_utc\", \"is_optional\": False, \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"sog\", \"is_optional\": False, \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"cog\", \"is_optional\": False, \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"true_heading\", \"is_optional\": False, \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"nav_status\", \"is_optional\": False, \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"rot\", \"is_optional\": False, \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"message_nr\", \"is_optional\": False, \"category\": DataCategory.DYNAMIC},\n",
    "        {\"name\": \"source\", \"is_optional\": False, \"category\": DataCategory.DYNAMIC},\n",
    "    ]\n",
    "}\n",
    "metadata = MetaData.from_dict(dataspec)\n",
    "data = generator.AISTestData(number_of_trajectories=1000, min_length=25, max_length=300)\n",
    "adf = AnnotatedDataFrame(data.dataframe, metadata, validation_mode=ValidationMode.UPDATE_DATA)\n",
    "adf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-processing\n",
    "Say we want to repeat this process on any data-set we read in. Then, we should create a `damast.core.dataprocessing.DataProcessingPipeline`.\n",
    "A pipeline consists of pipeline-elements, that is a set of transformations on the original dataset.\n",
    "We start by creating a Pipeline-element that drops all rows missing an `\"mmsi\"` entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from damast.data_handling.transformers.filters import DropMissing\n",
    "from damast.core.dataprocessing import DataProcessingPipeline\n",
    "pipeline = DataProcessingPipeline(name=\"Remove missing MMSI columns\",\n",
    "                                  base_dir=\"./output_dir\",\n",
    "                                  inplace_transformation=True)\n",
    "pipeline.add(name=\"Remove MMSI column\",\n",
    "             transformer=DropMissing(),\n",
    "             name_mappings={\"x\": \"mmsi\"})\n",
    "\n",
    "transformed_adf = pipeline.transform(adf)\n",
    "transformed_adf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "damast-test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
